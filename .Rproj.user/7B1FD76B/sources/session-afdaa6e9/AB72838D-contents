---
title: "LSTM Recurrent Neural Networks"
author: "Moise Brutus - Kevin Waisfeld - Michael Nhliziyo"
format: revealjs
---

# Introduction

## What is an LSTM?

-   LSTM networks are a type of recurrent neural network that works well with sequential data, such as time series data and text.

-   Such sequence prediction problems involve predicting the next value based on a given input.

-   We then plan on putting an LSTM model to the test by seeing how accurately it can predict financial time series data.

-   LSTM networks were mainly created to solve the exploding/vanishing gradient problem

-   Their capacity to model and understand long range dependencies makes them critical in executing various tasks.

# Data

## Background on the data

-   For this analysis, we'll be using historical time-series data for Apple and General Motors, a corporation listed on the NASDAQ Stock Exchange.

-   The data is sourced from Yahoo Finance using the yfinance package in python.

-   The resulting data file is relatively simple, comprised of only seven columns, with each row representing an individual trading day going back to five years.

## Variables

-   **Date** : This represents a specific trading day that the market was at least partially open.

-   **Open** : The price at the time of market opening on the given day.

-   **High** : The highest price that the stock reached on the given day.

-   **Low** : The lowest price that the stock reached on the given day.

-   **Close** : The price at the time of market closing on the given day.

## Additional Variables

-   In addition to the variables to the standard variables fetched from the Yahoo Finance API, we created our own columns to add to the dataset.

-   Simple Moving Average : A simple moving average (SMA) is created by taking the mean closing price of a stock over a given number of periods.

-   Exponential Moving Average : EMA's give additional weight to the most recent days.

## Data Summary

![](/datasummary.png){fig-align="center" width="733"}

# Methodology

## Activation Functions

-   The sigmoid and tanh activation functions are crucial for the different gates and operations of the LSTM architecture in a network.

    ![](/activationfun.png){fig-align="center" width="473"}

-   The sigmiod activaton function outputs a value between 0 and 1.

-   The tanh activation function outputs a value between -1 and 1.

## Gates

-   They are composed of four components; the cell,input gate, the output gate and a forget gate.

-   The gates are responsible for processing and regulating the information flowing in and out of the cell.

    ![](/lstm.jpeg){width="500" fig-align="center"}

## Forget Gate

-   The forget gate is responsible for discarding the information which is not gonna used in the next steps.

-   The closer the value of the information passed through the forget is to 0, the more likely is to be forgotten.

## Input Gate

-   The input gate charge of choosing which new data points to include in the cell state at a certain time step.

-   The input gate regulates the information flow by producing values between 0 and 1 using a sigmoid activation function.

## Output Gate

-   The output gate decides which cell state data should be carried over to the following time step and added to the network's output

-   It makes use of a sigmoid activation function and is essential to the LSTM's capacity to provide outputs that are aware of context.

# Analysis

## Implentation

-   Python
-   Pandas
-   Numpy
-   Tensorflow
-   Keras
-   Matplotlib

## Pre-Processing

-   Standardization

-   Normalization

-   80/20 Shuffled Split

## LSTM Model

LSTM_modelApple = ke.Sequential() LSTM_modelApple.add(LSTM(128, return_sequences=True, input_shape=(LSTM_Xtrain1.shape\[1\], 1))) LSTM_modelApple.add(LSTM(64, return_sequences=False)) LSTM_modelApple.add(Dense(25, activation='linear')) LSTM_modelApple.add(Dense(1))

## Model Summary

![](/ag1.png){fig-align="center"}

## Model Summary

![](/ag2.png){fig-align="center"}

# Results

## Results

-   Model was able to predict results of Apple's stock price exceptionally well

-   While 270 days looks a little messy on a chart, the predicted stock price was very close to the actual stock price on both the first 50 days of the dataset and the last 50

    ![](/sg1.png){fig-align="center"}

## Results Cont.

-   We also wanted to look at how the model would work at predicting days that were completely unseen in the dataset.

-   Our model was based on stock data running through the end of October 2023. So we picked two additional days in November to see how the model performs.

-   We saw that the predicted price for the two days we chose were also very close to the actual price.

    ![](/sg2.JPG.png){width="1009" fig-align="center"}

## Results Cont.

-   During the time-span of our dataset, Apple's stock had relatively low volatility and was a consistently rising stock. So we also wanted to see how the LSTM model performed on a stock that has been on a different trajectory.

-   We also wanted to see it's performance on another industry and sector of the economy, which is how we landed on General Motors.

## Results Cont.

-   During the same timespan, General Motors stock has had far more volatility and has been mostly stagnant.

    ![](/sg3.JPG){width="1507" fig-align="center"}

## Results Cont.

-   We saw the LSTM model perform just as well on the General Motors stock as it did on the Apple stock. We also saw good results when picking two days in November 2023, which were not contained in the original dataset.

    ![](/sg4.JPG){width="1054" fig-align="center"}

## Results Cont.

-   The number of epochs is an important hyperparameter that went into our analysis. With too few epochs, underfitting is a possibility. With too many epochs, overfitting the data is also a possibility.

-   We were able to run some tests with our data to see how the data performs based on the number of epochs selected.

## Results Cont.

-   We see both the underfitting and overfitting dilemma when looking at both extremes, only running 25 epochs or running 200.

    ![](/sg5.JPG){fig-align="center"}

# Conclusion

## Conclusion

-   We were able to build an LSTM model to accurately predict the price of a stock based on it's previous history, including previous closing prices and trading volume.

-   We tested our hyperparameters to find the best options for our model and adjusted it accordingly.

-   We were also able to replicate the success of our model using another, unrelated stock which has had a significantly different history.

-   Ultimately, our success shows that it might be possible to accurately predict stock market data using a time-series analysis such as LSTM.

## Conclusion Cont.

-   At the same time, there are some caveats to consider. While the prediction price is very close to the actual price, there is a difference. In commodity markets, a small difference can make a huge impact on whether trades are successful or not, especially in short-term trading.

-   Just because we can get close to a prediction price doesn't mean that using such a model is a wise trading strategy (which we would never suggest anyways!)

-   More research is required on using LSTM models in the financial markets, including during times of recession and economic downturn.

## Conclusion Cont.

-   Another caveat to consider is what the LSTM model is using to make its predictions. As it's a time-series analysis, the LSTM model is using history from previous trading days. It's then spitting out a result that very closely mimics the previous days price. In the long-term, predicting that tomorrow's closing price will be very close to today's closing price is generally going to be successful, but it doesn't make it a good trading strategy.

-   When we overlay a line of a stock's closing price with another line of it's one-day closing price (that is, the closing price the previous day), we see quite good results.

## Conclusion Cont.

-   Ultimately, our research and experiment has found that LSTM models do possess predictive capability when it comes to the financial markets, but that more research must be done before such models can have a major impact on financial markets.
